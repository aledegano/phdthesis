\select@language {italian}
\select@language {italian}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces An exploded view of the CMS detector in its current configuration.\relax }}{2}{figure.caption.4}
\contentsline {figure}{\numberline {1.2}{\ignorespaces (Left) A module of HGCAL, consisting of printed circuit board, silicon sensor and absorber. (Right) Two modules mounted on either sides of a copper tungsten absorber also used for the cooling of the system.\relax }}{4}{figure.caption.5}
\contentsline {figure}{\numberline {1.3}{\ignorespaces (Left) The final Electromagnetic HGCAL endcap carbon-fiber structure. (Right) The petals inserted into the slots of the structure.\relax }}{5}{figure.caption.6}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Number of transistor count in logarithmic scale with respect to the year of introduction. Credit to \href {https://commons.wikimedia.org/wiki/User:Wgsimon}{Wgsimon}, \href {http://creativecommons.org/licenses/by-sa/3.0/}{CC BY-SA 3.0}\relax }}{7}{figure.caption.7}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Maximum theoretical speedup for various values of $f$ as a function of the number of parallel processes. Credit to \href {https://en.wikipedia.org/wiki/User:Daniels220}{Daniels220}, \href {http://creativecommons.org/licenses/by-sa/3.0/}{CC BY-SA 3.0}\relax }}{9}{figure.caption.8}
\contentsline {figure}{\numberline {2.3}{\ignorespaces a) Scheme of a CPU where most of the transistors are dedicated to caches and control unit. b) Scheme of a GPU with most of the resources used for the numerous execution units.\relax }}{9}{figure.caption.9}
\contentsline {figure}{\numberline {2.4}{\ignorespaces A NVIDIA Kepler GPU equipped with 192 single-precision CUDA cores.\relax }}{11}{figure.caption.10}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Example of two CUDA streams execution.\relax }}{14}{figure.caption.12}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Example of a 2D tree building. $1^{st}$ step: find the middle point with respect to the $x$ axis and split the area in two equal sub-areas with a line passing through the point (blue line). $2^{nd}$ step: in each children find the median points and split further the children by a line constant in $y$ passing through them (red lines). $N^{th}$ step: all points belong to a leaf and all volumes are created.\relax }}{16}{figure.caption.13}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Volume Kd-tree build timings.\relax }}{23}{figure.caption.14}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Volume Kd-tree search times for CPU sequential and GPU parallel code\relax }}{24}{figure.caption.16}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Volume Kd-tree speedup between CPU sequential and GPU parallel search code\relax }}{24}{figure.caption.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }}{31}{figure.caption.18}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Time spent by the build of the KD-tree.\relax }}{32}{figure.caption.19}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }}{33}{figure.caption.20}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Search times for CPU sequential and GPU parallel code.\relax }}{33}{figure.caption.21}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Speedup between CPU sequential and GPU parallel code.\relax }}{34}{figure.caption.23}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{35}{figure.caption.26}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{35}{figure.caption.27}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Time spent by the build of the KD-tree on simulated data.\relax }}{36}{figure.caption.28}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Search times for CPU sequential and GPU parallel code on simulated data.\relax }}{37}{figure.caption.30}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Speedup between CPU sequential and GPU parallel code on simulated data.\relax }}{37}{figure.caption.31}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Kernel execution time for different number of CUDA streams.\relax }}{40}{figure.caption.32}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Setup of the Tegra K1 board and the power meter.\relax }}{44}{figure.caption.33}
\addvspace {10\p@ }

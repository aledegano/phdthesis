\chapter{K-Dimensional binary search tree}\label{ch:3}
A k-d tree is a data-structure used to partition a k-dimensional space and is a special case of a binary-search tree.

\section{General description of the KD-tree}
A binary tree is a data-structure in which each element of the data-set is hierarchically connected to the other elements which also constitute the so called nodes of the tree.\\
Each node has at most two children, usually referred to as left-child and right-child. Thus from every node of a binary tree develops another sub-tree. \\
The nodes of the tree that does not have any children are called Leaves.\\
A k-d tree subdivides a k-dimensional space in such a way that the relation between sub-spaces can be represented through a binary tree.
For the intents and purposes of this thesis from here we will consider k=3, therefore always referring to a three-dimensional Cartesian space, however all the following methods and techniques can be extended to any number of dimensions and any orthogonal basis.
  
\subsection{Building a 3D tree}
The procedure of the tree construction is recursive: a starting point is chosen and it will be called the root of the tree, a plane passing through the root point and orthogonal to one of the axis defines the regions of the two sub-trees children of root, for each of those a new root is chosen between the points of the sub-tree repeating the procedure until all the sub-trees contains no points, those are the leaves of the tree.\\
In order to construct a balanced tree, where each sub-tree of a given level contains the same amount of points, there are two requirements: the first is that the subdivision must be performed cycling along the axis, so if the first splitting is done by a plane orthogonal to X the second will be done with respect to Y, the third to Z, the fourth again through X and so on until the leaves are created.\\
The second requirements lies in chosing the root of each sub-tree in such a way that both of its sons will contain the same amount of points (with the exception of one point in case of odd numbering that will conventionally be assigned to the left son). To achieve that all the points of a sub-tree are sorted according to their coordinate in the axis along which the sub-tree will be divided, the root will be the middle point defined by that with as many points preceeding as many following it.\\
The relations between each node and its sons is then recorded and the procedure stops when all the leaves are created.

\subsection{Traversing a 3D tree}
The purpose of creating a binary tree data-structure is to greatly reduce the number of comparisons required to search a given point in the whole set.\\
The procedure is again recursive, let's consider for instance the search of the closest point in the set to an arbitrary point not included in the initial set: usign the same axis-cycling described in the building evaluate if the point is smaller or greater of the root along the axis picked. If it is smaller the search will continue on the left-child of the root, otherwise on the right-child. The second step is to compare the point to be searched with the node child of root chosen by the previous step, again comparing it along the next axis in the cycle (always maintaining the same axis-cycling order used in the construction). The procedure continues until it is reached a node without any child: a leaf, which is the closest point of the set to the input point.\\
From the procedure described above it is clear that this type of search discards half of the total volume at each step. It is therefore expected that the complexity of this search to be $\mathcal{O}(\log{} n)$ where the complexity of the "naive" method would be $\mathcal{O}(n^2)$ as it would require to compare the input point to every other point in the set.\\
The Nearest Neighbor search is just a slight variation of the above described procedure. Suppose to be searching the neighbors of a point in the data-set that lies within a cube centered on the input point. The search procedure for the "box" would be similar to the one explained for the point, the only caveat being that the box can be not only "left" or "right" of a given node but also intersecting it. In the case of intersection both child of the node will be considered for further searching and the node itself -even if it's not a leaf- will be considered a Nearest Neighbor as it lies in the search volume. It is clear that the complexity of this case has to be worse than that of a single point, in particular has been demonstrated \cite{worst-case-search} that the worse-case run-time is $\mathcal{O}(k \cdot N ^{1 - {1\over k}})$ for k dimensions.
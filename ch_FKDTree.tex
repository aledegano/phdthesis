\chapter{A better KD-tree implementation}\label{ch:fkdtree}
In this chapter we describe a different implementation of a KD-tree that fixes the issues of the volume KD-tree explained in Section \ref{sec:volumeKdAssessment} and implements a search much more suitable to a highly parallel computation. The implementation is again wrote in \CC\ and CUDA for the GPU relevant parts.

\section{Build of a left-balanced KD-tree}
A left-balanced binary tree is a tree in which the leaves only occupy the leftmost positions in the last level. This positioning can be applied to the leaves of a KD-tree as well by chosing to assign the leaves of the tree to the leftmost available parent.\\
In practice this can be achieved by assigning the index of each node of the tree to a pre-determined value evaluated by the node's depth in the tree and its relative position among the other nodes at the same depth.\\
The KD-tree nodes are assigned to a binary tree, therefore each node has two children in the next layer and the number of nodes $N_d$ at a given depth $d$ can be evaluated as $N_d = 2^d$ where $d = 0$ is the depth of the root. Moreover the indeces of the children of a given node of index $I_p$ can also be simply evaluated to be $I_{left} = I_p \cdot 2$ and $I_{right} = I_p \cdot 2 + 1$. Using this knowledge we assign to the nodes of the tree a pre-determined index.\\
For this implementation of KD-tree we also drop the feature used in the volume KD-tree to assign a volume to each node of the tree. In this implementation each node of the tree corresponds to one point of the data set.\\
By exploiting the predictive placement of the tree's nodes we can also implement a build procedure that is iterative instead of recursive: an outer loop visits all the layers of the tree until all the leaves are created, inside another internal loop -that spans the tree horizontaly- creates one by one the children of the nodes at the current depth, assigning them the index that can be evaluated as powers of 2 as described by the above formula. The inner loops ends when all the children of the next depth are created, and the outer loop ends when each point of the data set is a node of the tree.\\
We determine the point to assign to each node by a sort performed along an axis similar to the one described in Paragraph \ref{sec:volumeKDBuild}, however in this implementation we realize that there is no reason to sort all the points in the range, what is needed, indeed, is to find the median point among them along the sorting axis, and then the points with the coordinate along the splitting axis smaller on one side and those with greater coordinates on the other side: the relative sorting in this two sets is irrelevant and can be avoided to gain some performance. The STL library provides a function that just does that: \textit{std::nth\_element} which we include in the build procedure.\\
Algorithm \ref{fkdtree_build} shows how we implemented the features described above.\\

\begin{algorithm}
\caption{The build of a left-balanced KD-tree}
\label{fkdtree_build}
\begin{algorithmic}
\Procedure{BuildKDTree}{numberOfPoints, points}
  \State pointsToEvaluate $\gets$ 0
  \For{(thisDepth $<$ maximumDepth)}
  \State axis $\gets$ thisDepth $\bmod$ 3 \Comment 0 = $x$, 1 = $y$, 2 = $z$
	  \For{ (thisIndex $<$ thisDepth$^2$)}
	  	\State medianValue $\gets$ pointsToEvaluate[thisIndex] / 2
	  	\State sortedPoints $\gets$ std::nth\_element(pointsInThisNode, medianValue)
	  	\State thisIndex $\gets$ medianValue
	  	\State tree[thisIndex] $\gets$ points[thisIndex]
	  	\State pointsToEvaluate[leftSon] $\gets$ sortedPoints[0,thisIndex)
	  	\State pointsToEvaluate[rightSon] $\gets$ sortedPoints[thisIndex, lastIndex]
	  \EndFor
  \EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Iterative range search}
To perform a range search the algorithm takes a ``search box'' as argument for which it finds the points in the data set that are enclosed in it.\\
The search procedure, recursive by nature, is made iterative by exploiting the the predictible nodes placement described by the build procedure. Particularly, starting from the root node, the algorithm checks if the node -along the splitting axis defined by the tree's depth- is greater than the search box maximum vertex, smaller of the minimum vertex or if it lies in the search box. When the node is greater than the search box the search proceeds on the node's left-child, when is smaller on the right-child and when it lies within the search box both children are considered for the next step in the search and the node is recorded as a nearest neighbor and will not be checked again.\\
In order to make the above procedure iterative, avoiding the recursion, a loop is performed on all the nodes to compare the search box against. The iteration is initialized by adding to a \textit{queue} the root node index. The loop starts and compare the search box against the root, then one or both of its childrens are added to the queue while the node compared is removed from the queue. The next iteration of the cycle will compare the search box against the last element of the queue (e.g. the node(s) added on the previous step) and remove it from the queue while adding whichever children the search must proceed on. The loop repeats until the queue is empty which means that the leaves are all reached and all the nearest neighbors recorded.\\

\subsection{Fast bitwise operations}
At every step of the search the axis along which the current node has been created must be known. It can be easily deduced by knowing the depth of the tree the node is situated at, which in turns could be saved as part of the information of the node but we decided against it to reduce to the bare minimum the memory footprint of the array of nodes. The depth of the node in the tree, indeed, can be evaluated from the node index $I$ by inverting the formula described in the previous Section, that is: $d = \lfloor log_2(I) \rfloor$ which in \CC\ can be easily implemented with the embedded C-functions as: $d = floor(log(I,2))$.\\
However we analysed the performance of the above code and found that it is relatively expensive in execution time. Therefore we replaced the code based on the C-function with a custom function leveraging the bitwise operators: \code{((unsigned int) (31 - \_\_builtin\_clz( I | 1) ))}. Starting from the inner parts the \code{I | 1} cosiders the integer representing the index of the node as a sequence of bits and does the $OR$ with the bit $1$, this ensures that the function works also in the case of $I = 0$. Then \code{\_\_builtin\_clz()} counts the number of leading zeroes in the index of the node when represented in binary form. The total number of bits representing an \code{unsigned int} in most common computer is 32, therefore subtracting the number of leading zeroes of the index to 32 gives the logarithm in base two of the index. Subtracting one to that number and then performing the cast to \code{unsigned int} performs the equivalent of the \code{floor()} operation giving the expected result.\\
This seemingly harmless substitution in the code resulted in a very tangible increase in performance being up to ten times faster than the code using the C-functions.\\

\section{Validation}

\section{GPU porting}

\subsection{GPU queue}

\subsection{CUDA streams}

\subsection{CUDA threads per block}

\section{Performance analysis}

\subsection{Uniform random distribution}

\subsection{HGCAL simulated RecHits}

\section{Algorithm assessment}
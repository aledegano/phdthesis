\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}A better KD-tree implementation}{31}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:fkdtree}{{4}{31}{A better KD-tree implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Build of a left-balanced KD-tree}{31}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces The build of a left-balanced KD-tree\relax }}{32}{algorithm.4.1}}
\newlabel{fkdtree_build}{{4.1}{32}{The build of a left-balanced KD-tree\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Iterative range search}{32}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fast bitwise operations}{33}{subsection.4.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces Range search of the left-balanced KD-tree\relax }}{34}{algorithm.4.2}}
\newlabel{fkdtree_search}{{4.2}{34}{Range search of the left-balanced KD-tree\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Validation}{34}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}GPU porting}{35}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}GPU queue}{35}{subsection.4.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}CUDA streams}{35}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }}{36}{figure.caption.20}}
\newlabel{cuda_streams}{{4.1}{36}{Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Performance analysis}{36}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Uniform random distribution}{36}{subsection.4.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Time spent by the build of the KD-tree.\relax }}{37}{figure.caption.21}}
\newlabel{fkdtree_build_times}{{4.2}{37}{Time spent by the build of the KD-tree.\relax }{figure.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Selected search times for CPU sequential and GPU parallel code.\relax }}{37}{table.caption.24}}
\newlabel{fkdtree_times_tab}{{4.1}{37}{Selected search times for CPU sequential and GPU parallel code.\relax }{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }}{38}{figure.caption.22}}
\newlabel{fkdtree_streams}{{4.3}{38}{Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Search times for CPU sequential and GPU parallel code.\relax }}{38}{figure.caption.23}}
\newlabel{fkdtree_search_times}{{4.4}{38}{Search times for CPU sequential and GPU parallel code.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fixed maximum nearest neighbors}{38}{section*.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Speedup between CPU sequential and GPU parallel code.\relax }}{39}{figure.caption.25}}
\newlabel{fkdtree_speedup}{{4.5}{39}{Speedup between CPU sequential and GPU parallel code.\relax }{figure.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }}{39}{table.caption.27}}
\newlabel{fkdtree_times_fixedNN_tab}{{4.2}{39}{Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }{table.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}HGCAL simulated RecHits}{39}{subsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{40}{figure.caption.28}}
\newlabel{fkdtree_times_fixedNN_searches}{{4.6}{40}{Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{40}{figure.caption.29}}
\newlabel{fkdtree_times_fixedNN_speedup}{{4.7}{40}{Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Time spent by the build of the KD-tree on simulated data.\relax }}{41}{figure.caption.30}}
\newlabel{fkdtree_build_sim_times}{{4.8}{41}{Time spent by the build of the KD-tree on simulated data.\relax }{figure.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }}{41}{table.caption.31}}
\newlabel{fkdtree_times_sim_tab}{{4.3}{41}{Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }{table.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Search times for CPU sequential and GPU parallel code on simulated data.\relax }}{42}{figure.caption.32}}
\newlabel{fkdtree_search_times}{{4.9}{42}{Search times for CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Speedup between CPU sequential and GPU parallel code on simulated data.\relax }}{42}{figure.caption.33}}
\newlabel{fkdtree_speedup}{{4.10}{42}{Speedup between CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.33}{}}
\citation{iso_stl}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Algorithm assessment}{43}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Build complexity}{43}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}CPU sequential search time}{43}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}GPU parallel search time}{43}{subsection.4.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Speedup}{44}{subsection.4.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Kernel execution time for different number of CUDA streams.\relax }}{45}{figure.caption.34}}
\newlabel{nvvp_streams}{{4.11}{45}{Kernel execution time for different number of CUDA streams.\relax }{figure.caption.34}{}}
\@setckpt{ch_FKDTree}{
\setcounter{page}{46}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{3}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{50}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{float@type}{8}
\setcounter{OptionTest}{0}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{19}
\setcounter{ALG@rem}{19}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{linenumber}{1066}
\setcounter{LN@truepage}{51}
\setcounter{section@level}{2}
}

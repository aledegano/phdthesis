\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}A better KD-tree implementation}{22}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:fkdtree}{{4}{22}{A better KD-tree implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Build of a left-balanced KD-tree}{22}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces The build of a left-balanced KD-tree\relax }}{23}{algorithm.4.1}}
\newlabel{fkdtree_build}{{4.1}{23}{The build of a left-balanced KD-tree\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Iterative range search}{23}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fast bitwise operations}{24}{subsection.4.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces Range search of the left-balanced KD-tree\relax }}{25}{algorithm.4.2}}
\newlabel{fkdtree_search}{{4.2}{25}{Range search of the left-balanced KD-tree\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Validation}{25}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}GPU porting}{26}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}GPU queue}{26}{subsection.4.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}CUDA streams}{26}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }}{27}{figure.caption.15}}
\newlabel{cuda_streams}{{4.1}{27}{Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Performance analysis}{27}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Uniform random distribution}{27}{subsection.4.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Time spent by the build of the KD-tree.\relax }}{28}{figure.caption.16}}
\newlabel{fkdtree_build_times}{{4.2}{28}{Time spent by the build of the KD-tree.\relax }{figure.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Selected search times for CPU sequential and GPU parallel code.\relax }}{28}{table.caption.19}}
\newlabel{fkdtree_times_tab}{{4.1}{28}{Selected search times for CPU sequential and GPU parallel code.\relax }{table.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }}{29}{figure.caption.17}}
\newlabel{fkdtree_streams}{{4.3}{29}{Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Search times for CPU sequential and GPU parallel code.\relax }}{29}{figure.caption.18}}
\newlabel{fkdtree_search_times}{{4.4}{29}{Search times for CPU sequential and GPU parallel code.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fixed maximum nearest neighbors}{29}{section*.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Speedup between CPU sequential and GPU parallel code.\relax }}{30}{figure.caption.20}}
\newlabel{fkdtree_speedup}{{4.5}{30}{Speedup between CPU sequential and GPU parallel code.\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }}{30}{table.caption.22}}
\newlabel{fkdtree_times_fixedNN_tab}{{4.2}{30}{Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}HGCAL simulated RecHits}{30}{subsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{31}{figure.caption.23}}
\newlabel{fkdtree_times_fixedNN_searches}{{4.6}{31}{Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{31}{figure.caption.24}}
\newlabel{fkdtree_times_fixedNN_speedup}{{4.7}{31}{Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Time spent by the build of the KD-tree on simulated data.\relax }}{32}{figure.caption.25}}
\newlabel{fkdtree_build_sim_times}{{4.8}{32}{Time spent by the build of the KD-tree on simulated data.\relax }{figure.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }}{32}{table.caption.26}}
\newlabel{fkdtree_times_sim_tab}{{4.3}{32}{Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }{table.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Search times for CPU sequential and GPU parallel code on simulated data.\relax }}{33}{figure.caption.27}}
\newlabel{fkdtree_search_times}{{4.9}{33}{Search times for CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Speedup between CPU sequential and GPU parallel code on simulated data.\relax }}{33}{figure.caption.28}}
\newlabel{fkdtree_speedup}{{4.10}{33}{Speedup between CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.28}{}}
\citation{iso_stl}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Algorithm assessment}{34}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Build complexity}{34}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}CPU sequential search time}{34}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}GPU parallel search time}{34}{subsection.4.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Speedup}{35}{subsection.4.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Kernel execution time for different number of CUDA streams.\relax }}{36}{figure.caption.29}}
\newlabel{nvvp_streams}{{4.11}{36}{Kernel execution time for different number of CUDA streams.\relax }{figure.caption.29}{}}
\@setckpt{ch_FKDTree}{
\setcounter{page}{37}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{3}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{45}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{float@type}{8}
\setcounter{OptionTest}{0}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{19}
\setcounter{ALG@rem}{19}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{linenumber}{832}
\setcounter{LN@truepage}{41}
\setcounter{section@level}{2}
}

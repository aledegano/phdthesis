\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}A better KD-tree implementation}{26}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:fkdtree}{{4}{26}{A better KD-tree implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Build of a left-balanced KD-tree}{26}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces The build of a left-balanced KD-tree\relax }}{27}{algorithm.4.1}}
\newlabel{fkdtree_build}{{4.1}{27}{The build of a left-balanced KD-tree\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Iterative range search}{27}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fast bitwise operations}{28}{subsection.4.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces Range search of the left-balanced KD-tree\relax }}{29}{algorithm.4.2}}
\newlabel{fkdtree_search}{{4.2}{29}{Range search of the left-balanced KD-tree\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Validation}{29}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}GPU porting}{30}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}GPU queue}{30}{subsection.4.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}CUDA streams}{30}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }}{31}{figure.caption.18}}
\newlabel{cuda_streams}{{4.1}{31}{Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Performance analysis}{31}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Uniform random distribution}{31}{subsection.4.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Time spent by the build of the KD-tree.\relax }}{32}{figure.caption.19}}
\newlabel{fkdtree_build_times}{{4.2}{32}{Time spent by the build of the KD-tree.\relax }{figure.caption.19}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Selected search times for CPU sequential and GPU parallel code.\relax }}{32}{table.caption.22}}
\newlabel{fkdtree_times_tab}{{4.1}{32}{Selected search times for CPU sequential and GPU parallel code.\relax }{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }}{33}{figure.caption.20}}
\newlabel{fkdtree_streams}{{4.3}{33}{Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Search times for CPU sequential and GPU parallel code.\relax }}{33}{figure.caption.21}}
\newlabel{fkdtree_search_times}{{4.4}{33}{Search times for CPU sequential and GPU parallel code.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fixed maximum nearest neighbors}{33}{section*.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Speedup between CPU sequential and GPU parallel code.\relax }}{34}{figure.caption.23}}
\newlabel{fkdtree_speedup}{{4.5}{34}{Speedup between CPU sequential and GPU parallel code.\relax }{figure.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }}{34}{table.caption.25}}
\newlabel{fkdtree_times_fixedNN_tab}{{4.2}{34}{Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}HGCAL simulated RecHits}{34}{subsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{35}{figure.caption.26}}
\newlabel{fkdtree_times_fixedNN_searches}{{4.6}{35}{Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{35}{figure.caption.27}}
\newlabel{fkdtree_times_fixedNN_speedup}{{4.7}{35}{Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Time spent by the build of the KD-tree on simulated data.\relax }}{36}{figure.caption.28}}
\newlabel{fkdtree_build_sim_times}{{4.8}{36}{Time spent by the build of the KD-tree on simulated data.\relax }{figure.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }}{36}{table.caption.29}}
\newlabel{fkdtree_times_sim_tab}{{4.3}{36}{Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }{table.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Search times for CPU sequential and GPU parallel code on simulated data.\relax }}{37}{figure.caption.30}}
\newlabel{fkdtree_search_times}{{4.9}{37}{Search times for CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Speedup between CPU sequential and GPU parallel code on simulated data.\relax }}{37}{figure.caption.31}}
\newlabel{fkdtree_speedup}{{4.10}{37}{Speedup between CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.31}{}}
\citation{iso_stl}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Algorithm assessment}{38}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Build complexity}{38}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}CPU sequential search time}{38}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}GPU parallel search time}{38}{subsection.4.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Speedup}{39}{subsection.4.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Kernel execution time for different number of CUDA streams.\relax }}{40}{figure.caption.32}}
\newlabel{nvvp_streams}{{4.11}{40}{Kernel execution time for different number of CUDA streams.\relax }{figure.caption.32}{}}
\@setckpt{ch_FKDTree}{
\setcounter{page}{41}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{3}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{46}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{float@type}{8}
\setcounter{OptionTest}{0}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{19}
\setcounter{ALG@rem}{19}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{linenumber}{932}
\setcounter{LN@truepage}{45}
\setcounter{section@level}{2}
}

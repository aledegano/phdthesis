\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}A better KD-tree implementation}{19}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:fkdtree}{{4}{19}{A better KD-tree implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Build of a left-balanced KD-tree}{19}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces The build of a left-balanced KD-tree\relax }}{20}{algorithm.4.1}}
\newlabel{fkdtree_build}{{4.1}{20}{The build of a left-balanced KD-tree\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Iterative range search}{20}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fast bitwise operations}{21}{subsection.4.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces Range search of the left-balanced KD-tree\relax }}{22}{algorithm.4.2}}
\newlabel{fkdtree_search}{{4.2}{22}{Range search of the left-balanced KD-tree\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Validation}{22}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}GPU porting}{23}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}GPU queue}{23}{subsection.4.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}CUDA streams}{23}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }}{24}{figure.caption.13}}
\newlabel{cuda_streams}{{4.1}{24}{Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Performance analysis}{24}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Uniform random distribution}{24}{subsection.4.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Time spent by the build of the KD-tree.\relax }}{25}{figure.caption.14}}
\newlabel{fkdtree_build_times}{{4.2}{25}{Time spent by the build of the KD-tree.\relax }{figure.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Selected search times for CPU sequential and GPU parallel code.\relax }}{25}{table.caption.17}}
\newlabel{fkdtree_times_tab}{{4.1}{25}{Selected search times for CPU sequential and GPU parallel code.\relax }{table.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }}{26}{figure.caption.15}}
\newlabel{fkdtree_streams}{{4.3}{26}{Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Search times for CPU sequential and GPU parallel code.\relax }}{26}{figure.caption.16}}
\newlabel{fkdtree_search_times}{{4.4}{26}{Search times for CPU sequential and GPU parallel code.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fixed maximum nearest neighbors}{26}{section*.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Speedup between CPU sequential and GPU parallel code.\relax }}{27}{figure.caption.18}}
\newlabel{fkdtree_speedup}{{4.5}{27}{Speedup between CPU sequential and GPU parallel code.\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }}{27}{table.caption.20}}
\newlabel{fkdtree_times_fixedNN_tab}{{4.2}{27}{Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}HGCAL simulated RecHits}{27}{subsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{28}{figure.caption.21}}
\newlabel{fkdtree_times_fixedNN_searches}{{4.6}{28}{Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{28}{figure.caption.22}}
\newlabel{fkdtree_times_fixedNN_speedup}{{4.7}{28}{Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Time spent by the build of the KD-tree on simulated data.\relax }}{29}{figure.caption.23}}
\newlabel{fkdtree_build_sim_times}{{4.8}{29}{Time spent by the build of the KD-tree on simulated data.\relax }{figure.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }}{29}{table.caption.24}}
\newlabel{fkdtree_times_sim_tab}{{4.3}{29}{Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Search times for CPU sequential and GPU parallel code on simulated data.\relax }}{30}{figure.caption.25}}
\newlabel{fkdtree_search_times}{{4.9}{30}{Search times for CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Speedup between CPU sequential and GPU parallel code on simulated data.\relax }}{30}{figure.caption.26}}
\newlabel{fkdtree_speedup}{{4.10}{30}{Speedup between CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.26}{}}
\citation{iso_stl}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Algorithm assessment}{31}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Build complexity}{31}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}CPU sequential search time}{31}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}GPU parallel search time}{31}{subsection.4.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Speedup}{32}{subsection.4.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Kernel execution time for different number of CUDA streams.\relax }}{33}{figure.caption.27}}
\newlabel{nvvp_streams}{{4.11}{33}{Kernel execution time for different number of CUDA streams.\relax }{figure.caption.27}{}}
\@setckpt{ch_FKDTree}{
\setcounter{page}{34}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{3}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{42}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{float@type}{8}
\setcounter{OptionTest}{0}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{19}
\setcounter{ALG@rem}{19}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{linenumber}{763}
\setcounter{LN@truepage}{38}
\setcounter{section@level}{2}
}

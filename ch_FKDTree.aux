\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}A better KD-tree implementation}{17}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:fkdtree}{{4}{17}{A better KD-tree implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Build of a left-balanced KD-tree}{17}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces The build of a left-balanced KD-tree\relax }}{18}{algorithm.4.1}}
\newlabel{fkdtree_build}{{4.1}{18}{The build of a left-balanced KD-tree\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Iterative range search}{18}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fast bitwise operations}{19}{subsection.4.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces Range search of the left-balanced KD-tree\relax }}{20}{algorithm.4.2}}
\newlabel{fkdtree_search}{{4.2}{20}{Range search of the left-balanced KD-tree\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Validation}{20}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}GPU porting}{21}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}GPU queue}{21}{subsection.4.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}CUDA streams}{21}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }}{22}{figure.caption.11}}
\newlabel{cuda_streams}{{4.1}{22}{Interleaving of four asyncronous CUDA streams. H2D: host to device process, D2H: device to host, Kernel: code execution.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Performance analysis}{22}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Uniform random distribution}{22}{subsection.4.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Time spent by the build of the KD-tree.\relax }}{23}{figure.caption.12}}
\newlabel{fkdtree_build_times}{{4.2}{23}{Time spent by the build of the KD-tree.\relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Selected search times for CPU sequential and GPU parallel code.\relax }}{23}{table.caption.15}}
\newlabel{fkdtree_times_tab}{{4.1}{23}{Selected search times for CPU sequential and GPU parallel code.\relax }{table.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }}{24}{figure.caption.13}}
\newlabel{fkdtree_streams}{{4.3}{24}{Relative performance gain between multiple CUDA streams with respect to the single stream.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Search times for CPU sequential and GPU parallel code.\relax }}{24}{figure.caption.14}}
\newlabel{fkdtree_search_times}{{4.4}{24}{Search times for CPU sequential and GPU parallel code.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fixed maximum nearest neighbors}{24}{section*.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Speedup between CPU sequential and GPU parallel code.\relax }}{25}{figure.caption.16}}
\newlabel{fkdtree_speedup}{{4.5}{25}{Speedup between CPU sequential and GPU parallel code.\relax }{figure.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }}{25}{table.caption.18}}
\newlabel{fkdtree_times_fixedNN_tab}{{4.2}{25}{Selected search times for CPU sequential and GPU parallel code for fixed number of NN.\relax }{table.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}HGCAL simulated RecHits}{25}{subsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{26}{figure.caption.19}}
\newlabel{fkdtree_times_fixedNN_searches}{{4.6}{26}{Search times for CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }}{26}{figure.caption.20}}
\newlabel{fkdtree_times_fixedNN_speedup}{{4.7}{26}{Speedup between CPU sequential and GPU parallel code for fixed maximum number of nearest neighbors.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Time spent by the build of the KD-tree on simulated data.\relax }}{27}{figure.caption.21}}
\newlabel{fkdtree_build_sim_times}{{4.8}{27}{Time spent by the build of the KD-tree on simulated data.\relax }{figure.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }}{27}{table.caption.22}}
\newlabel{fkdtree_times_sim_tab}{{4.3}{27}{Selected search times for CPU sequential and GPU parallel code searching simulated data.\relax }{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Search times for CPU sequential and GPU parallel code on simulated data.\relax }}{28}{figure.caption.23}}
\newlabel{fkdtree_search_times}{{4.9}{28}{Search times for CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Speedup between CPU sequential and GPU parallel code on simulated data.\relax }}{28}{figure.caption.24}}
\newlabel{fkdtree_speedup}{{4.10}{28}{Speedup between CPU sequential and GPU parallel code on simulated data.\relax }{figure.caption.24}{}}
\citation{iso_stl}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Algorithm assessment}{29}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Build complexity}{29}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}CPU sequential search time}{29}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}GPU parallel search time}{29}{subsection.4.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Speedup}{30}{subsection.4.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Kernel execution time for different number of CUDA streams.\relax }}{31}{figure.caption.25}}
\newlabel{nvvp_streams}{{4.11}{31}{Kernel execution time for different number of CUDA streams.\relax }{figure.caption.25}{}}
\@setckpt{ch_FKDTree}{
\setcounter{page}{32}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{3}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{40}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{float@type}{8}
\setcounter{OptionTest}{0}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{19}
\setcounter{ALG@rem}{19}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{linenumber}{720}
\setcounter{LN@truepage}{36}
\setcounter{section@level}{2}
}
